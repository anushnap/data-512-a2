{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anushna Prakash  \n",
    "DATA 512 - Human-Centered Data Science  \n",
    "October 14, 2021  \n",
    "# A2 - Bias in Data\n",
    "The goal of this assignment is to explore the concept of bias through data on Wikipedia articles - specifically, articles on political figures from a variety of countries. For this assignment, you will combine a dataset of Wikipedia articles with a dataset of country populations, and use a machine learning service called ORES to estimate the quality of each article.\n",
    "You are expected to perform an analysis of how the coverage of politicians on Wikipedia and the quality of articles about politicians varies between countries. Your analysis will consist of a series of tables that show:  \n",
    "- the countries with the greatest and least coverage of politicians on Wikipedia compared to their population.  \n",
    "- the countries with the highest and lowest proportion of high quality articles about politicians.  \n",
    "- a ranking of geographic regions by articles-per-person and proportion of high quality articles.  \n",
    "You are also expected to write a short reflection on the project that focuses on how both your findings from this analysis and the process you went through to reach those findings helps you understand the causes and consequences of biased data in large, complex data science projects.\n",
    "\n",
    "## Step 0: Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:55% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Make notebook width wider\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:55% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See README.md for where data was downloaded from originally.\n",
    "# Import from data_raw folder assuming we are running from the src folder.\n",
    "page_data = pd.read_csv('../data_raw/country/data/page_data.csv')\n",
    "population = pd.read_csv('../data_raw/WPDS_2020_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:Zimbabwe-politician-stub</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Template:Uganda-politician-stub</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>391862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Template:Namibia-politician-stub</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>391862409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page   country     rev_id\n",
       "0  Template:ZambiaProvincialMinisters    Zambia  235107991\n",
       "1                      Bir I of Kanem      Chad  355319463\n",
       "2   Template:Zimbabwe-politician-stub  Zimbabwe  391862046\n",
       "3     Template:Uganda-politician-stub    Uganda  391862070\n",
       "4    Template:Namibia-politician-stub   Namibia  391862409"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47197 entries, 0 to 47196\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   page     47197 non-null  object\n",
      " 1   country  47197 non-null  object\n",
      " 2   rev_id   47197 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "page_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page       0\n",
       "country    0\n",
       "rev_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>World</td>\n",
       "      <td>2019</td>\n",
       "      <td>7772.850</td>\n",
       "      <td>7772850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>1337.918</td>\n",
       "      <td>1337918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>244.344</td>\n",
       "      <td>244344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZ</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.357</td>\n",
       "      <td>44357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>100.803</td>\n",
       "      <td>100803000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FIPS             Name        Type  TimeFrame  Data (M)  \\\n",
       "0            WORLD            WORLD       World       2019  7772.850   \n",
       "1           AFRICA           AFRICA  Sub-Region       2019  1337.918   \n",
       "2  NORTHERN AFRICA  NORTHERN AFRICA  Sub-Region       2019   244.344   \n",
       "3               DZ          Algeria     Country       2019    44.357   \n",
       "4               EG            Egypt     Country       2019   100.803   \n",
       "\n",
       "   Population  \n",
       "0  7772850000  \n",
       "1  1337918000  \n",
       "2   244344000  \n",
       "3    44357000  \n",
       "4   100803000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   FIPS        233 non-null    object \n",
      " 1   Name        234 non-null    object \n",
      " 2   Type        234 non-null    object \n",
      " 3   TimeFrame   234 non-null    int64  \n",
      " 4   Data (M)    234 non-null    float64\n",
      " 5   Population  234 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS          1\n",
       "Name          0\n",
       "Type          0\n",
       "TimeFrame     0\n",
       "Data (M)      0\n",
       "Population    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.541</td>\n",
       "      <td>2541000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS     Name     Type  TimeFrame  Data (M)  Population\n",
       "62  NaN  Namibia  Country       2019     2.541     2541000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.loc[population['FIPS'].isnull(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning the Data  \n",
    "Both `page_data.csv` and `WPDS_2020_data.csv` contain some rows that you will need to filter out and/or ignore when you combine the datasets in the next step. In the case of `page_data.csv`, the dataset contains some page names that start with the string \"Template:\". These pages are not Wikipedia articles, and should not be included in your analysis.  \n",
    "Similarly, `WPDS_2020_data.csv` contains some rows that provide cumulative regional population counts, rather than country-level counts. These rows are distinguished by having ALL CAPS values in the `geography` field (e.g. AFRICA, OCEANIA). These rows won't match the country values in `page_data.csv`, but you will want to retain them (either in the original file, or a separate file) so that you can report coverage and quality by region in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove page names that begin with 'Template:' since these are not wikipedia articles\n",
    "page_data = page_data.loc[~page_data['page'].str.startswith('Template:'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Information Minister of the Palestinian Nation...</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>393276188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yos Por</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>393822005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Julius Gregr</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>395521877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Edvard Gregr</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>395526568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47192</th>\n",
       "      <td>Yahya Jammeh</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>807482007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47193</th>\n",
       "      <td>Lucius Fairchild</td>\n",
       "      <td>United States</td>\n",
       "      <td>807483006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47194</th>\n",
       "      <td>Fahd of Saudi Arabia</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>807483153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47195</th>\n",
       "      <td>Francis Fessenden</td>\n",
       "      <td>United States</td>\n",
       "      <td>807483270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47196</th>\n",
       "      <td>Ajay Kannoujiya</td>\n",
       "      <td>India</td>\n",
       "      <td>807484325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46701 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    page  \\\n",
       "1                                         Bir I of Kanem   \n",
       "10     Information Minister of the Palestinian Nation...   \n",
       "12                                               Yos Por   \n",
       "23                                          Julius Gregr   \n",
       "24                                          Edvard Gregr   \n",
       "...                                                  ...   \n",
       "47192                                       Yahya Jammeh   \n",
       "47193                                   Lucius Fairchild   \n",
       "47194                               Fahd of Saudi Arabia   \n",
       "47195                                  Francis Fessenden   \n",
       "47196                                    Ajay Kannoujiya   \n",
       "\n",
       "                     country     rev_id  \n",
       "1                       Chad  355319463  \n",
       "10     Palestinian Territory  393276188  \n",
       "12                  Cambodia  393822005  \n",
       "23            Czech Republic  395521877  \n",
       "24            Czech Republic  395526568  \n",
       "...                      ...        ...  \n",
       "47192                 Gambia  807482007  \n",
       "47193          United States  807483006  \n",
       "47194           Saudi Arabia  807483153  \n",
       "47195          United States  807483270  \n",
       "47196                  India  807484325  \n",
       "\n",
       "[46701 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can I just filter on type == 'country'? Why do we have to check if its all caps. This method ends up including the Channel Islands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have regional population counts and not country-level counts. Ex: AFRICA, OCEANIA\n",
    "# population = population.loc[population['Type'] == 'Country', ]\n",
    "# population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 210 entries, 3 to 233\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   FIPS        209 non-null    object \n",
      " 1   Name        210 non-null    object \n",
      " 2   Type        210 non-null    object \n",
      " 3   TimeFrame   210 non-null    int64  \n",
      " 4   Data (M)    210 non-null    float64\n",
      " 5   Population  210 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "original_population = population.copy()\n",
    "population = population.loc[~population['Name'].str.isupper(), ]\n",
    "population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Channel Islands</td>\n",
       "      <td>Channel Islands</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.172</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FIPS             Name        Type  TimeFrame  Data (M)  \\\n",
       "168  Channel Islands  Channel Islands  Sub-Region       2019     0.172   \n",
       "\n",
       "     Population  \n",
       "168      172000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.loc[population['Type'] != 'Country',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Getting Article Quality Predictions\n",
    "\n",
    "Now you need to get the predicted quality scores for each article in the Wikipedia dataset. We're using a machine learning system called ORES. This was originally an acronym for \"Objective Revision Evaluation Service\" but was simply renamed “ORES”. ORES is a machine learning tool that can provide estimates of Wikipedia article quality. The article quality estimates are, from best to worst:  \n",
    "- FA - Featured article  \n",
    "- GA - Good article  \n",
    "- B - B-class article  \n",
    "- C - C-class article  \n",
    "- Start - Start-class article  \n",
    "- Stub - Stub-class article  \n",
    "\n",
    "These were learned based on articles in Wikipedia that were peer-reviewed using the Wikipedia content assessment procedures.These quality classes are a sub-set of quality assessment categories developed by Wikipedia editors. For this assignment, you only need to know that these categories exist, and that ORES will assign one of these 6 categories to any rev_id you send it.  \n",
    "In order to get article predictions for each article in the Wikipedia dataset, you will first need to read page_data.csv into Python (or R), and then read through the dataset line by line, using the value of the rev_id column to make an API query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't able to use the `ores` package directly to do all of the revid calls at once, so instead I'll use the Ores API and send the `rev_id`s in batches not exceeding 50 ids per batch to prevent api call failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Fill with your own information if reproducing\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/anushnap',\n",
    "    'From': 'anushnap@uw.edu'\n",
    "}\n",
    "\n",
    "endpoint = 'https://ores.wikimedia.org/v3/scores/enwiki?models=articlequality&revids={revid}'\n",
    "\n",
    "df = page_data.copy()\n",
    "n_batches = math.ceil(len(df) / 49)\n",
    "df['row_num'] = np.arange(len(df))\n",
    "df['batch_num'] = df['row_num'] % n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run these cells if you are re-running and re-downloading the predictions from the API. Otherwise, skip this block and download the already-saved data from .json files in the `data_raw/api_dump` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(n_batches):\n",
    "#     id_str = '|'.join(df.loc[df['batch_num'] == n, 'rev_id'].astype(str))\n",
    "#     params = {\n",
    "#         \"revid\" : id_str\n",
    "#     }\n",
    "    \n",
    "#     call = api_call(endpoint, params)\n",
    "#     filename = 'ores_scores_enwiki_articlequality_batchnum-' + str(n) + '.json'\n",
    "    \n",
    "#     with open('../data_raw/api_dump/' + filename, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(call, f, ensure_ascii = False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data back in and get the prediction if it exists\n",
    "for n in range(n_batches):\n",
    "    filename = '../data_raw/api_dump/ores_scores_enwiki_articlequality_batchnum-' + str(n) + '.json'\n",
    "    temp = json.load(open(filename))['enwiki']['scores']\n",
    "    \n",
    "    for i in temp:\n",
    "        int_id = int(i)\n",
    "#         print(int_id)\n",
    "        try:\n",
    "            prediction = temp[i]['articlequality']['score']['prediction']\n",
    "        except KeyError:\n",
    "            prediction = np.nan\n",
    "        finally:\n",
    "            df.loc[(df['rev_id'] == int_id), 'prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page            0\n",
       "country         0\n",
       "rev_id          0\n",
       "row_num         0\n",
       "batch_num       0\n",
       "prediction    276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of the articles for which we were unable to get a prediction and save this in `data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['prediction'].isnull()].to_csv('../data_clean/articles_missing_prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Combining the Datasets\n",
    "\n",
    "Some processing of the data will be necessary! In particular, you'll need to - after retrieving and including the ORES data for each article - merge the wikipedia data and population data together. Both have fields containing country names for just that purpose. After merging the data, you'll invariably run into entries which cannot be merged. Either the population dataset does not have an entry for the equivalent Wikipedia country, or vise versa.  \n",
    "Please remove any rows that do not have matching data, and output them to a CSV file called: `wp_wpds_countries-no_match.csv`  \n",
    "Consolidate the remaining data into a single CSV file called: `wp_wpds_politicians_by_country.csv`  \n",
    "\n",
    "The schema for that file should look something like this:  \n",
    "| Column |  \n",
    "| ------ |  \n",
    "| country |\n",
    "| article_name |\n",
    "| revision_id |\n",
    "| article_quality_est. |\n",
    "| population |\n",
    "\n",
    "Note: `revision_id` here is the same thing as `rev_id`, which you used to get scores from ORES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all data together\n",
    "full_results = df.merge(population, how = 'outer', left_on = 'country', right_on = 'Name')\n",
    "\n",
    "# Find data that is missing in either table and save assuming we are running from src folder\n",
    "missing_results = full_results.loc[(full_results['country'].isnull() | full_results['Name'].isnull())]\n",
    "missing_results.to_csv('../data_clean/wp_wpds_countries-no_match.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(missing_results['country'].unique())\n",
    "print(missing_results['Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Western Sahara', \"Cote d'Ivoire\", 'Mayotte', 'Reunion',\n",
       "       'Congo, Dem. Rep.', 'eSwatini', 'El Salvador', 'Honduras',\n",
       "       'Curacao', 'Puerto Rico', 'St. Kitts-Nevis', 'Saint Lucia',\n",
       "       'St. Vincent and the Grenadines', 'Georgia', 'Oman', 'Brunei',\n",
       "       'Timor-Leste', 'China, Hong Kong SAR', 'China, Macao SAR',\n",
       "       'Channel Islands', 'Czechia', 'North Macedonia',\n",
       "       'French Polynesia', 'Guam', 'New Caledonia', 'Palau', 'Samoa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
