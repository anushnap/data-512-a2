{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anushna Prakash  \n",
    "DATA 512 - Human-Centered Data Science  \n",
    "October 14, 2021  \n",
    "# A2 - Bias in Data\n",
    "The goal of this assignment is to explore the concept of bias through data on Wikipedia articles - specifically, articles on political figures from a variety of countries. For this assignment, you will combine a dataset of Wikipedia articles with a dataset of country populations, and use a machine learning service called ORES to estimate the quality of each article.\n",
    "You are expected to perform an analysis of how the coverage of politicians on Wikipedia and the quality of articles about politicians varies between countries. Your analysis will consist of a series of tables that show:  \n",
    "- the countries with the greatest and least coverage of politicians on Wikipedia compared to their population.  \n",
    "- the countries with the highest and lowest proportion of high quality articles about politicians.  \n",
    "- a ranking of geographic regions by articles-per-person and proportion of high quality articles.  \n",
    "You are also expected to write a short reflection on the project that focuses on how both your findings from this analysis and the process you went through to reach those findings helps you understand the causes and consequences of biased data in large, complex data science projects.\n",
    "\n",
    "## Step 0: Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:55% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Make notebook width wider\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:55% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See README.md for where data was downloaded from originally.\n",
    "# Import from data_raw folder assuming we are running from the src folder.\n",
    "page_data = pd.read_csv('../data_raw/country/data/page_data.csv')\n",
    "population = pd.read_csv('../data_raw/WPDS_2020_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:Zimbabwe-politician-stub</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Template:Uganda-politician-stub</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>391862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Template:Namibia-politician-stub</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>391862409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page   country     rev_id\n",
       "0  Template:ZambiaProvincialMinisters    Zambia  235107991\n",
       "1                      Bir I of Kanem      Chad  355319463\n",
       "2   Template:Zimbabwe-politician-stub  Zimbabwe  391862046\n",
       "3     Template:Uganda-politician-stub    Uganda  391862070\n",
       "4    Template:Namibia-politician-stub   Namibia  391862409"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47197 entries, 0 to 47196\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   page     47197 non-null  object\n",
      " 1   country  47197 non-null  object\n",
      " 2   rev_id   47197 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "page_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page       0\n",
       "country    0\n",
       "rev_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>WORLD</td>\n",
       "      <td>World</td>\n",
       "      <td>2019</td>\n",
       "      <td>7772.850</td>\n",
       "      <td>7772850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>1337.918</td>\n",
       "      <td>1337918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>244.344</td>\n",
       "      <td>244344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZ</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.357</td>\n",
       "      <td>44357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>100.803</td>\n",
       "      <td>100803000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FIPS             Name        Type  TimeFrame  Data (M)  \\\n",
       "0            WORLD            WORLD       World       2019  7772.850   \n",
       "1           AFRICA           AFRICA  Sub-Region       2019  1337.918   \n",
       "2  NORTHERN AFRICA  NORTHERN AFRICA  Sub-Region       2019   244.344   \n",
       "3               DZ          Algeria     Country       2019    44.357   \n",
       "4               EG            Egypt     Country       2019   100.803   \n",
       "\n",
       "   Population  \n",
       "0  7772850000  \n",
       "1  1337918000  \n",
       "2   244344000  \n",
       "3    44357000  \n",
       "4   100803000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234 entries, 0 to 233\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   FIPS        233 non-null    object \n",
      " 1   Name        234 non-null    object \n",
      " 2   Type        234 non-null    object \n",
      " 3   TimeFrame   234 non-null    int64  \n",
      " 4   Data (M)    234 non-null    float64\n",
      " 5   Population  234 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS          1\n",
       "Name          0\n",
       "Type          0\n",
       "TimeFrame     0\n",
       "Data (M)      0\n",
       "Population    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Country</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.541</td>\n",
       "      <td>2541000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS     Name     Type  TimeFrame  Data (M)  Population\n",
       "62  NaN  Namibia  Country       2019     2.541     2541000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.loc[population['FIPS'].isna(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning the Data  \n",
    "Both `page_data.csv` and `WPDS_2020_data.csv` contain some rows that you will need to filter out and/or ignore when you combine the datasets in the next step. In the case of `page_data.csv`, the dataset contains some page names that start with the string \"Template:\". These pages are not Wikipedia articles, and should not be included in your analysis.  \n",
    "Similarly, `WPDS_2020_data.csv` contains some rows that provide cumulative regional population counts, rather than country-level counts. These rows are distinguished by having ALL CAPS values in the `geography` field (e.g. AFRICA, OCEANIA). These rows won't match the country values in `page_data.csv`, but you will want to retain them (either in the original file, or a separate file) so that you can report coverage and quality by region in the analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove page names that begin with 'Template:' since these are not wikipedia articles\n",
    "page_data = page_data.loc[~page_data['page'].str.startswith('Template:'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Information Minister of the Palestinian Nation...</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>393276188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yos Por</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>393822005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Julius Gregr</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>395521877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Edvard Gregr</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>395526568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47192</th>\n",
       "      <td>Yahya Jammeh</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>807482007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47193</th>\n",
       "      <td>Lucius Fairchild</td>\n",
       "      <td>United States</td>\n",
       "      <td>807483006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47194</th>\n",
       "      <td>Fahd of Saudi Arabia</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>807483153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47195</th>\n",
       "      <td>Francis Fessenden</td>\n",
       "      <td>United States</td>\n",
       "      <td>807483270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47196</th>\n",
       "      <td>Ajay Kannoujiya</td>\n",
       "      <td>India</td>\n",
       "      <td>807484325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46701 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    page  \\\n",
       "1                                         Bir I of Kanem   \n",
       "10     Information Minister of the Palestinian Nation...   \n",
       "12                                               Yos Por   \n",
       "23                                          Julius Gregr   \n",
       "24                                          Edvard Gregr   \n",
       "...                                                  ...   \n",
       "47192                                       Yahya Jammeh   \n",
       "47193                                   Lucius Fairchild   \n",
       "47194                               Fahd of Saudi Arabia   \n",
       "47195                                  Francis Fessenden   \n",
       "47196                                    Ajay Kannoujiya   \n",
       "\n",
       "                     country     rev_id  \n",
       "1                       Chad  355319463  \n",
       "10     Palestinian Territory  393276188  \n",
       "12                  Cambodia  393822005  \n",
       "23            Czech Republic  395521877  \n",
       "24            Czech Republic  395526568  \n",
       "...                      ...        ...  \n",
       "47192                 Gambia  807482007  \n",
       "47193          United States  807483006  \n",
       "47194           Saudi Arabia  807483153  \n",
       "47195          United States  807483270  \n",
       "47196                  India  807484325  \n",
       "\n",
       "[46701 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can I just filter on type == 'country'? Why do we have to check if its all caps. This method ends up including the Channel Islands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have regional population counts and not country-level counts. Ex: AFRICA, OCEANIA\n",
    "# population = population.loc[population['Type'] == 'Country', ]\n",
    "# population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 210 entries, 3 to 233\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   FIPS        209 non-null    object \n",
      " 1   Name        210 non-null    object \n",
      " 2   Type        210 non-null    object \n",
      " 3   TimeFrame   210 non-null    int64  \n",
      " 4   Data (M)    210 non-null    float64\n",
      " 5   Population  210 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "original_population = population.copy()\n",
    "population = population.loc[~population['Name'].str.isupper(), ]\n",
    "population.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data (M)</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Channel Islands</td>\n",
       "      <td>Channel Islands</td>\n",
       "      <td>Sub-Region</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.172</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FIPS             Name        Type  TimeFrame  Data (M)  \\\n",
       "168  Channel Islands  Channel Islands  Sub-Region       2019     0.172   \n",
       "\n",
       "     Population  \n",
       "168      172000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.loc[population['Type'] != 'Country',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.to_csv('../data_clean/WPDS_countries_only.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Getting Article Quality Predictions\n",
    "\n",
    "Now you need to get the predicted quality scores for each article in the Wikipedia dataset. We're using a machine learning system called ORES. This was originally an acronym for \"Objective Revision Evaluation Service\" but was simply renamed “ORES”. ORES is a machine learning tool that can provide estimates of Wikipedia article quality. The article quality estimates are, from best to worst:  \n",
    "- FA - Featured article  \n",
    "- GA - Good article  \n",
    "- B - B-class article  \n",
    "- C - C-class article  \n",
    "- Start - Start-class article  \n",
    "- Stub - Stub-class article  \n",
    "\n",
    "These were learned based on articles in Wikipedia that were peer-reviewed using the Wikipedia content assessment procedures.These quality classes are a sub-set of quality assessment categories developed by Wikipedia editors. For this assignment, you only need to know that these categories exist, and that ORES will assign one of these 6 categories to any rev_id you send it.  \n",
    "In order to get article predictions for each article in the Wikipedia dataset, you will first need to read page_data.csv into Python (or R), and then read through the dataset line by line, using the value of the rev_id column to make an API query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't able to use the `ores` package directly to do all of the revid calls at once, so instead I'll use the Ores API and send the `rev_id`s in batches not exceeding 50 ids per batch to prevent api call failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Fill with your own information if reproducing\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/anushnap',\n",
    "    'From': 'anushnap@uw.edu'\n",
    "}\n",
    "\n",
    "endpoint = 'https://ores.wikimedia.org/v3/scores/enwiki?models=articlequality&revids={revid}'\n",
    "\n",
    "df = page_data.copy()\n",
    "n_batches = math.ceil(len(df) / 49)\n",
    "df['row_num'] = np.arange(len(df))\n",
    "df['batch_num'] = df['row_num'] % n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run these cells if you are re-running and re-downloading the predictions from the API. Otherwise, skip this block and download the already-saved data from .json files in the `data_raw/api_dump` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(n_batches):\n",
    "#     id_str = '|'.join(df.loc[df['batch_num'] == n, 'rev_id'].astype(str))\n",
    "#     params = {\n",
    "#         \"revid\" : id_str\n",
    "#     }\n",
    "    \n",
    "#     call = api_call(endpoint, params)\n",
    "#     filename = 'ores_scores_enwiki_articlequality_batchnum-' + str(n) + '.json'\n",
    "    \n",
    "#     with open('../data_raw/api_dump/' + filename, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(call, f, ensure_ascii = False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data back in and get the prediction if it exists\n",
    "for n in range(n_batches):\n",
    "    filename = '../data_raw/api_dump/ores_scores_enwiki_articlequality_batchnum-' + str(n) + '.json'\n",
    "    temp = json.load(open(filename))['enwiki']['scores']\n",
    "    \n",
    "    for i in temp:\n",
    "        int_id = int(i)\n",
    "#         print(int_id)\n",
    "        try:\n",
    "            prediction = temp[i]['articlequality']['score']['prediction']\n",
    "        except KeyError:\n",
    "            prediction = np.nan\n",
    "        finally:\n",
    "            df.loc[(df['rev_id'] == int_id), 'prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page            0\n",
       "country         0\n",
       "rev_id          0\n",
       "row_num         0\n",
       "batch_num       0\n",
       "prediction    276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of the articles for which we were unable to get a prediction and save this in `data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['prediction'].isnull()].to_csv('../data_clean/articles_missing_prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Combining the Datasets\n",
    "\n",
    "Some processing of the data will be necessary! In particular, you'll need to - after retrieving and including the ORES data for each article - merge the wikipedia data and population data together. Both have fields containing country names for just that purpose. After merging the data, you'll invariably run into entries which cannot be merged. Either the population dataset does not have an entry for the equivalent Wikipedia country, or vise versa.  \n",
    "Please remove any rows that do not have matching data, and output them to a CSV file called: `wp_wpds_countries-no_match.csv`  \n",
    "Consolidate the remaining data into a single CSV file called: `wp_wpds_politicians_by_country.csv`  \n",
    "\n",
    "The schema for that file should look something like this:  \n",
    "\n",
    "| Column |\n",
    "|--------|\n",
    "| country      |\n",
    "| article_name      |\n",
    "| revision_id      |\n",
    "| article_quality_est.      |\n",
    "| population      |\n",
    "\n",
    "\n",
    "Note: `revision_id` here is the same thing as `rev_id`, which you used to get scores from ORES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all data together\n",
    "full_results = df.merge(population, how = 'outer', left_on = 'country', right_on = 'Name')\n",
    "\n",
    "# Find data that is missing in either table and save assuming we are running from src folder\n",
    "missing_results = full_results.loc[(full_results['country'].isnull() | full_results['Name'].isnull())]\n",
    "missing_results.to_csv('../data_clean/wp_wpds_countries-no_match.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Czech Republic' 'Salvadoran' 'Rhodesian' 'Congo, Dem. Rep. of'\n",
      " 'East Timorese' 'Faroese' 'Cape Colony' 'South Korean' 'Samoan'\n",
      " 'Montserratian' 'Pitcairn Islands' 'Saint Kitts and Nevis' 'Macedonia'\n",
      " 'Abkhazia' 'Niuean' 'Ivorian' 'Carniolan' 'Saint Lucian'\n",
      " 'South African Republic' 'Hondura' 'Incan' 'Chechen' 'Jersey' 'Guernsey'\n",
      " 'Saint Vincent and the Grenadines' 'South Ossetian' 'Cook Island' 'Omani'\n",
      " 'Tokelauan' 'Swaziland' 'Dagestani' 'Greenlandic' 'Ossetian' 'Palauan'\n",
      " 'Somaliland' 'Rojava' nan]\n",
      "[nan 'Western Sahara' \"Cote d'Ivoire\" 'Mayotte' 'Reunion'\n",
      " 'Congo, Dem. Rep.' 'eSwatini' 'El Salvador' 'Honduras' 'Curacao'\n",
      " 'Puerto Rico' 'St. Kitts-Nevis' 'Saint Lucia'\n",
      " 'St. Vincent and the Grenadines' 'Georgia' 'Oman' 'Brunei' 'Timor-Leste'\n",
      " 'China, Hong Kong SAR' 'China, Macao SAR' 'Channel Islands' 'Czechia'\n",
      " 'North Macedonia' 'French Polynesia' 'Guam' 'New Caledonia' 'Palau'\n",
      " 'Samoa']\n"
     ]
    }
   ],
   "source": [
    "print(missing_results['country'].unique())\n",
    "print(missing_results['Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data together, but only non-missing data\n",
    "results = df.merge(population, how = 'inner', left_on = 'country', right_on = 'Name')\\\n",
    "    [['country', 'page', 'rev_id', 'prediction', 'Population']]\\\n",
    "    .rename(\n",
    "        {'page': 'article_name', 'rev_id': 'revision_id', 'prediction': 'article_quality_est.', 'Population': 'population'}, \n",
    "        axis = 1)\n",
    "\n",
    "# Write results to a table assuming we are in the src folder\n",
    "results.to_csv('../data_clean/wp_wpds_politicians_by_country.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analysis\n",
    "\n",
    "Your analysis will consist of calculating the proportion (as a percentage) of articles-per-population and high-quality articles for each country AND for each geographic region. By \"high quality\" articles, in this case we mean the number of articles about politicians in a given country that ORES predicted would be in either the \"FA\" (featured article) or \"GA\" (good article) classes.  \n",
    "Examples:  \n",
    "- if a country has a population of 10,000 people, and you found 10 FA or GA class articles about politicians from that country, then the percentage of articles-per-population would be .1%.  \n",
    "- if a country has 10 articles about politicians, and 2 of them are FA or GA class articles, then the percentage of high-quality articles would be 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High quality articles are ones that are classified as FA or GA\n",
    "results['high_quality'] = results['article_quality_est.'].isin(['FA', 'GA'])\n",
    "country_stats = results.groupby(['country', 'population', 'high_quality'], dropna = False, as_index = False)\\\n",
    "    .agg({'revision_id': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_high_quality_articles</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>percentage_of_articles</th>\n",
       "      <th>percentage_of_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928000</td>\n",
       "      <td>13</td>\n",
       "      <td>322</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>3.339499e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2838000</td>\n",
       "      <td>3</td>\n",
       "      <td>457</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>1.057082e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>44357000</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>4.508871e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>45377000</td>\n",
       "      <td>16</td>\n",
       "      <td>491</td>\n",
       "      <td>0.032587</td>\n",
       "      <td>3.526015e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>2956000</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>1.691475e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>321000</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>9.345794e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>28645000</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>1.047303e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>96209000</td>\n",
       "      <td>13</td>\n",
       "      <td>187</td>\n",
       "      <td>0.069519</td>\n",
       "      <td>1.351225e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>29826000</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>1.005834e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>14863000</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>1.345623e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  population  num_high_quality_articles  total_articles  \\\n",
       "1    Afghanistan    38928000                         13             322   \n",
       "3        Albania     2838000                          3             457   \n",
       "5        Algeria    44357000                          2             116   \n",
       "10     Argentina    45377000                         16             491   \n",
       "12       Armenia     2956000                          5             196   \n",
       "..           ...         ...                        ...             ...   \n",
       "319      Vanuatu      321000                          3              60   \n",
       "321    Venezuela    28645000                          3             131   \n",
       "323      Vietnam    96209000                         13             187   \n",
       "325        Yemen    29826000                          3             118   \n",
       "328     Zimbabwe    14863000                          2             165   \n",
       "\n",
       "     percentage_of_articles  percentage_of_pop  \n",
       "1                  0.040373       3.339499e-07  \n",
       "3                  0.006565       1.057082e-06  \n",
       "5                  0.017241       4.508871e-08  \n",
       "10                 0.032587       3.526015e-07  \n",
       "12                 0.025510       1.691475e-06  \n",
       "..                      ...                ...  \n",
       "319                0.050000       9.345794e-06  \n",
       "321                0.022901       1.047303e-07  \n",
       "323                0.069519       1.351225e-07  \n",
       "325                0.025424       1.005834e-07  \n",
       "328                0.012121       1.345623e-07  \n",
       "\n",
       "[146 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_stats['total_ids'] = country_stats.groupby(['country', 'population'])['revision_id'].transform('sum')\n",
    "country_stats['percentage_of_articles'] = country_stats['revision_id'] / country_stats['total_ids']\n",
    "country_stats['percentage_of_pop'] = country_stats['revision_id'] / country_stats['population']\n",
    "articles_by_country = country_stats.loc[country_stats['high_quality'] == True].drop(['high_quality'], axis = 1)\\\n",
    "    .rename({'revision_id': 'num_high_quality_articles', 'total_ids': 'total_articles'}, axis = 1)\n",
    "articles_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made this region hierarchy table by myself manually in Microsoft Excel. It has each country with its regional hierarchy classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Region_0</th>\n",
       "      <th>Region_1</th>\n",
       "      <th>Region_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>World</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>World</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Libya</td>\n",
       "      <td>World</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>World</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>World</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>World</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>World</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>World</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>World</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>World</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Region_0 Region_1         Region_2\n",
       "0            Algeria    World   AFRICA  NORTHERN AFRICA\n",
       "1              Egypt    World   AFRICA  NORTHERN AFRICA\n",
       "2              Libya    World   AFRICA  NORTHERN AFRICA\n",
       "3            Morocco    World   AFRICA  NORTHERN AFRICA\n",
       "4              Sudan    World   AFRICA  NORTHERN AFRICA\n",
       "..               ...      ...      ...              ...\n",
       "205            Samoa    World  OCEANIA          OCEANIA\n",
       "206  Solomon Islands    World  OCEANIA          OCEANIA\n",
       "207            Tonga    World  OCEANIA          OCEANIA\n",
       "208           Tuvalu    World  OCEANIA          OCEANIA\n",
       "209          Vanuatu    World  OCEANIA          OCEANIA\n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_hierarchy = pd.read_csv('../data_clean/WPDS_countries_with_region_hierarchy.csv')\n",
    "region_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create mapping of all countries and their regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Results\n",
    "\n",
    "Your results from this analysis will be published in the form of data tables. You are being asked to produce six total tables, that show:  \n",
    "- Top 10 countries by coverage: 10 highest-ranked countries in terms of number of politician articles as a proportion of country population  \n",
    "- Bottom 10 countries by coverage: 10 lowest-ranked countries in terms of number of politician articles as a proportion of country population  \n",
    "- Top 10 countries by relative quality: 10 highest-ranked countries in terms of the relative proportion of politician articles that are of GA and FA-quality  \n",
    "- Bottom 10 countries by relative quality: 10 lowest-ranked countries in terms of the relative proportion of politician articles that are of GA and FA-quality  \n",
    "- Geographic regions by coverage: Ranking of geographic regions (in descending order) in terms of the total count of politician articles from countries in each region as a proportion of total regional population  \n",
    "- Geographic regions by coverage: Ranking of geographic regions (in descending order) in terms of the relative proportion of politician articles from countries in each region that are of GA and FA-quality  \n",
    "\n",
    "Embed these tables in your Jupyter notebook. You do not need to graph or otherwise visualize the data for this assignment, although you are welcome to do so in addition to generating the data tables described above, if you wish.  \n",
    "Reminder: you will find the list of geographic regions, which countries are in each region, and total regional population in the raw `WPDS_2020_data.csv` file. See \"Step 2: Cleaning the data\" above for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
